# Neural-Network-from-Scratch-XOR-Problem
 This code implements a neural network from scratch in Python to solve the XOR problem. The network consists of one hidden layer with a configurable number of neurons and uses the sigmoid activation function. The backpropagation algorithm is employed for training, and the mean squared error (MSE) is used as the loss function. 

# Neural Network for XOR Problem

This repository contains a Python implementation of a neural network designed to solve the XOR problem.

## Description

The code demonstrates building a neural network from scratch, including:

- Defining the network architecture (one hidden layer with configurable neurons)
- Implementing the sigmoid activation function and its derivative
- Using the backpropagation algorithm for training
- Calculating the mean squared error (MSE) loss
- Tracking and visualizing loss and accuracy during training

## Usage

1.  Run the code in a Python environment (e.g., Google Colab).
2.  Modify the parameters such as the number of neurons in the hidden layer and the learning rate to experiment with different network configurations.
3.  Observe the training process through the loss and accuracy plots.

## Dependencies

- NumPy
- Pandas
- Matplotlib

## Example

The code includes an example where the XOR problem is solved with 4 neurons in the hidden layer and a learning rate of 0.4. The training process is visualized with plots of loss and accuracy over epochs.
